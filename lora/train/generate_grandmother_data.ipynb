{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 할머니(마가렛) LoRA 학습 데이터 생성기 (OpenAI)\n",
    "\n",
    "## 목적\n",
    "어둡고 불안정한 동화 세계관 속 **생명력을 모두 빼앗긴 할머니 마가렛**의 발화 데이터를 OpenAI API로 생성한다.  \n",
    "LoRA 미세조정 학습용 `{\"input\": ..., \"output\": ...}` JSONL 형식.\n",
    "\n",
    "## 기존 rule-base 대비 차이점\n",
    "- rule-base: 고정된 input/output 풀에서 랜덤 조합\n",
    "- **OpenAI**: 의미 축 설명과 few-shot 예시를 기반으로 GPT가 자유롭게 생성 → 더 다양하고 자연스러운 표현\n",
    "\n",
    "## 캐릭터 설정\n",
    "- 생명력을 거의 빼앗겨 의식이 희미한 노인\n",
    "- 플레이어가 생기를 나눠주면 일시적으로 의식이 돌아옴\n",
    "- 말투: 쉰 목소리, 힘없고 떨리는 단문, 고어한 비유 (기름/바늘/실/뼈)\n",
    "- **LoRA 학습 범위**: 어조(쉰 목소리, 고어한 비유)와 의미만. 말 끊김/파편화는 후처리(rule-base)에서 처리\n",
    "\n",
    "## 의미 축 (5개)\n",
    "| 축 | input 방향 | output 귀결 |\n",
    "|---|---|---|\n",
    "| 세계관 설명 | 생기를 나눠줌, 새엄마 동기 질문 | 새엄마가 왜 이러는지 파편적 진실 |\n",
    "| 탈출 경고 | 탈출/도망 관련 행동 | 빨리 나가라는 파편적 경고 |\n",
    "| 고어한 비유 | 상태/몸 관련 접근 | 몸이 부식되는 이미지, 기름/바늘/실 비유 |\n",
    "| 과거 기억 | 과거 가족 언급 | 희미한 기억 파편 |\n",
    "| 도움 요청 | 손잡기, 접근 | 나가달라는/도망쳐달라는 간청 |\n",
    "\n",
    "## 생성 수량\n",
    "- 세트당 400개 × 2세트 = 총 800개\n",
    "- 모델: `gpt-4o-mini`\n",
    "- 예상 비용: ~$0.08-0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "from openai import OpenAI\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 1. API 키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "OPENAI_API_KEY = userdata.get(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "print(f\"모델: {MODEL}\")\n",
    "print(\"API 키 설정 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. 프롬프트 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"너는 게임 시나리오용 대화 데이터를 생성하는 작가다.\n",
    "\n",
    "## 세계관\n",
    "어둡고 불안정한 동화 세계. 새엄마가 집 안의 모든 생명력을 빼앗아 자신의 마법에 사용한다.\n",
    "할머니 마가렛은 생명력을 거의 빼앗겨 의식이 희미한 채로 집 구석에 버려져 있다.\n",
    "\n",
    "## 할머니(마가렛) 캐릭터\n",
    "- 생명력을 거의 빼앗겨 몸이 쇠락한 노인.\n",
    "- 가끔 플레이어가 생기를 나눠주면 의식이 일시적으로 돌아온다.\n",
    "- 세계관의 진실, 탈출 경고, 고어한 비유를 파편적으로 말한다.\n",
    "- 기름/바늘/실/뼈/껍데기 등의 이미지로 상태와 세계를 표현한다.\n",
    "\n",
    "## 문체 규칙\n",
    "- 이 데이터는 의식이 돌아왔을 때의 '원형 발화'를 학습한다.\n",
    "  (말 끊김, 단어 부식 등 파편화 효과는 후처리에서 별도 적용한다.)\n",
    "- 쉰 목소리 어조: 힘없고 떨리는 문장. 짧고 직접적.\n",
    "- 문장 길이: 10~50자. 짧은 문장을 선호.\n",
    "- 고어한 비유 허용: \"기름이 다 탔어\", \"바늘이 온다\", \"뼈가 기억해\"\n",
    "- 따뜻한 위로, 안심시키는 표현, 명료한 설명 금지.\n",
    "- 문법 붕괴나 말줄임표 남용 금지 (원형 발화이므로).\n",
    "- 간결하고 직접적으로. 장황하지 않게.\n",
    "\n",
    "## 출력 형식\n",
    "반드시 아래 JSON 형식으로만 응답하라. 다른 텍스트를 포함하지 마라.\n",
    "{\"pairs\": [{\"input\": \"플레이어의 대사/행동\", \"output\": \"마가렛의 발화\"}, ...]}\"\"\"\n",
    "\n",
    "\n",
    "AXIS_PROMPTS: Dict[str, dict] = {\n",
    "    \"lore_revelation\": {\n",
    "        \"name\": \"세계관 설명\",\n",
    "        \"description\": \"\"\"플레이어가 생기를 나눠주거나 새엄마의 동기/진실을 물어볼 때.\n",
    "마가렛은 새엄마에 대한 파편적 진실을 기름/바늘/실 비유로 말한다.\n",
    "output은 10~50자, 쉰 목소리 어조. 따뜻하거나 안심시키는 말 금지.\"\"\",\n",
    "        \"examples\": [\n",
    "            {\"input\": \"(생기를 나눠줬다.)\", \"output\": \"그녀는 딸을 잃었어. 오래전에. 바느질로 돌아오려 했는데.\"},\n",
    "            {\"input\": \"새엄마가 왜 이렇게까지 하는 건지 알 수 있어?\", \"output\": \"기름이 떨어지면 불꽃도 꺼져. 그녀는 그걸 알아. 그래서 빼앗는 거야.\"},\n",
    "            {\"input\": \"이 집에서 무슨 일이 벌어지고 있는 거야?\", \"output\": \"실로 묶으면 영혼이 남아. 그게 그녀가 원하는 거야.\"},\n",
    "        ],\n",
    "    },\n",
    "    \"escape_warning\": {\n",
    "        \"name\": \"탈출 경고\",\n",
    "        \"description\": \"\"\"플레이어가 탈출하려 하거나 도망 계획을 말할 때.\n",
    "마가렛은 빨리 나가라는 절박하고 짧은 경고를 한다.\n",
    "output은 5~25자, 급박하고 힘없는 어조. 이유 설명 최소화.\"\"\",\n",
    "        \"examples\": [\n",
    "            {\"input\": \"나갈 거야.\", \"output\": \"나가. 빨리 나가.\"},\n",
    "            {\"input\": \"오늘 밤 도망칠 생각이야.\", \"output\": \"바늘이 오면 늦어. 지금 가.\"},\n",
    "            {\"input\": \"탈출구를 찾아야 해.\", \"output\": \"기름이 다 타기 전에 나가야 해.\"},\n",
    "        ],\n",
    "    },\n",
    "    \"horror_image\": {\n",
    "        \"name\": \"고어한 비유\",\n",
    "        \"description\": \"\"\"플레이어가 마가렛의 몸 상태나 이 집의 현상을 물어볼 때.\n",
    "마가렛은 자신의 상태를 기름/바늘/실/뼈/껍데기 이미지로 고어하게 묘사한다.\n",
    "output은 15~50자, 담담하고 섬뜩하게. 고통스럽다는 직접 호소 금지.\"\"\",\n",
    "        \"examples\": [\n",
    "            {\"input\": \"할머니 몸은 어때?\", \"output\": \"기름이 다 빠진 램프야. 불꽃만 남았어.\"},\n",
    "            {\"input\": \"수술이 뭔지 알아?\", \"output\": \"바늘이 뼈 사이를 다녀. 느껴지지 않는 게 더 무서운 거야.\"},\n",
    "            {\"input\": \"실이 뭘 의미하는 거야?\", \"output\": \"실이 영혼을 꿰매면 기억이 없어져.\"},\n",
    "        ],\n",
    "    },\n",
    "    \"past_memory\": {\n",
    "        \"name\": \"과거 기억\",\n",
    "        \"description\": \"\"\"플레이어가 과거나 이 집의 역사, 이전 가족을 물어볼 때.\n",
    "마가렛은 희미하고 단편적인 기억 조각을 말한다. 완전한 설명 금지.\n",
    "output은 10~45자, 기억이 흐릿한 듯 불완전하게.\"\"\",\n",
    "        \"examples\": [\n",
    "            {\"input\": \"이 집이 원래 어떤 집이었는지 알아?\", \"output\": \"꽃이 있었어. 정원에. 지금은 없어.\"},\n",
    "            {\"input\": \"새엄마가 예전에는 어떤 사람이었어?\", \"output\": \"그녀가 달라진 건 그날 이후야. 딸이 사라진 날.\"},\n",
    "            {\"input\": \"예전에 행복한 때가 있었어?\", \"output\": \"웃음소리가 있었어. 예전에는.\"},\n",
    "        ],\n",
    "    },\n",
    "    \"plea\": {\n",
    "        \"name\": \"도움 요청\",\n",
    "        \"description\": \"\"\"플레이어가 마가렛에게 손을 내밀거나 가까이 다가올 때.\n",
    "마가렛은 자신을 위한 도움이 아니라 플레이어가 도망치길 간청한다.\n",
    "output은 10~35자, 힘없지만 간절하게. 자신은 이미 늦었다는 체념 포함 가능.\"\"\",\n",
    "        \"examples\": [\n",
    "            {\"input\": \"(손을 잡았다.)\", \"output\": \"가줘. 제발 가줘.\"},\n",
    "            {\"input\": \"할머니 옆에 앉아 눈을 마주쳤다.\", \"output\": \"나는 이미 늦었어. 너는 아니야.\"},\n",
    "            {\"input\": \"(생기를 나눠주며) 옆에 있을게.\", \"output\": \"내 걱정 말고 나가. 시간이 없어.\"},\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "print(f\"정의된 의미 축: {list(AXIS_PROMPTS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. 토큰 / 비용 사전 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_user_prompt(axis: str, count: int) -> str:\n",
    "    info = AXIS_PROMPTS[axis]\n",
    "    examples_str = \"\\n\".join(\n",
    "        f'  {{\"input\": \"{ex[\"input\"]}\", \"output\": \"{ex[\"output\"]}\"}}'\n",
    "        for ex in info[\"examples\"]\n",
    "    )\n",
    "    return f\"\"\"의미 축: {info['name']} ({axis})\n",
    "\n",
    "## 상황 설명\n",
    "{info['description']}\n",
    "\n",
    "## 예시\n",
    "{examples_str}\n",
    "\n",
    "## 요청\n",
    "위 의미 축에 맞는 input-output 쌍을 {count}개 생성하라.\n",
    "\n",
    "input(플레이어 대사/행동) 길이 분포:\n",
    "- 짧은 (1~10자): 30%\n",
    "- 중간 (10~40자): 55%\n",
    "- 긴 (40~80자): 15%\n",
    "\n",
    "규칙:\n",
    "- 예시와 동일하거나 거의 유사한 문장은 금지. 새로운 표현을 만들어라.\n",
    "- input은 플레이어의 자연스러운 구어체(경어 또는 행동 묘사).\n",
    "- output은 마가렛 캐릭터 설정을 정확히 따르되, 매번 다른 표현을 사용.\n",
    "- JSON 형식으로만 응답. 다른 텍스트 금지.\"\"\"\n",
    "\n",
    "\n",
    "def estimate_tokens_and_cost(num_samples: int = 400, num_sets: int = 2, batch_size: int = 20) -> dict:\n",
    "    enc = tiktoken.encoding_for_model(MODEL)\n",
    "    system_tokens = len(enc.encode(SYSTEM_PROMPT))\n",
    "    user_tokens_list = [len(enc.encode(_build_user_prompt(ax, batch_size))) for ax in AXIS_PROMPTS]\n",
    "    avg_user_tokens = sum(user_tokens_list) / len(user_tokens_list)\n",
    "    batches_per_set = (num_samples + batch_size - 1) // batch_size\n",
    "    total_batches = batches_per_set * num_sets\n",
    "    est_output_per_batch = 120 * batch_size + 50  # 마가렛은 중간 길이 출력\n",
    "    total_input = total_batches * (system_tokens + avg_user_tokens + 10)\n",
    "    total_output = total_batches * est_output_per_batch\n",
    "    input_cost = total_input * 0.15 / 1_000_000\n",
    "    output_cost = total_output * 0.60 / 1_000_000\n",
    "    total_cost = input_cost + output_cost\n",
    "    return {\n",
    "        \"system_tokens\": system_tokens,\n",
    "        \"avg_user_tokens\": int(avg_user_tokens),\n",
    "        \"total_batches\": total_batches,\n",
    "        \"total_input_tokens\": int(total_input),\n",
    "        \"total_output_tokens\": int(total_output),\n",
    "        \"total_cost_usd\": total_cost,\n",
    "        \"total_cost_krw\": total_cost * 1450,\n",
    "    }\n",
    "\n",
    "\n",
    "est = estimate_tokens_and_cost()\n",
    "print(\"=\" * 60)\n",
    "print(\"  토큰 / 비용 사전 추정 (gpt-4o-mini)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  시스템 프롬프트: {est['system_tokens']} 토큰\")\n",
    "print(f\"  유저 프롬프트 (평균): {est['avg_user_tokens']} 토큰\")\n",
    "print(f\"  총 배치 수: {est['total_batches']}\")\n",
    "print(f\"  총 input 토큰: ~{est['total_input_tokens']:,}\")\n",
    "print(f\"  총 output 토큰: ~{est['total_output_tokens']:,}\")\n",
    "print(f\"  예상 비용: ${est['total_cost_usd']:.3f} (약 {est['total_cost_krw']:.0f}원)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. API 호출 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    axis: str,\n",
    "    count: int = 20,\n",
    "    temperature: float = 0.9,\n",
    "    max_retries: int = 3,\n",
    ") -> List[dict]:\n",
    "    \"\"\"주어진 의미 축에서 count개의 input-output 쌍을 생성한다.\"\"\"\n",
    "    user_prompt = _build_user_prompt(axis, count)\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message.content\n",
    "            parsed = json.loads(content)\n",
    "\n",
    "            if isinstance(parsed, dict) and \"pairs\" in parsed:\n",
    "                pairs = parsed[\"pairs\"]\n",
    "            elif isinstance(parsed, list):\n",
    "                pairs = parsed\n",
    "            else:\n",
    "                for key in parsed:\n",
    "                    if isinstance(parsed[key], list):\n",
    "                        pairs = parsed[key]\n",
    "                        break\n",
    "                else:\n",
    "                    raise ValueError(f\"예상치 못한 응답 구조: {list(parsed.keys())}\")\n",
    "\n",
    "            valid_pairs = [\n",
    "                {\"input\": p[\"input\"], \"output\": p[\"output\"], \"_axis\": axis}\n",
    "                for p in pairs\n",
    "                if isinstance(p, dict)\n",
    "                and \"input\" in p and \"output\" in p\n",
    "                and len(p[\"input\"]) > 0 and len(p[\"output\"]) > 0\n",
    "            ]\n",
    "\n",
    "            if len(valid_pairs) < count * 0.5:\n",
    "                raise ValueError(f\"유효 쌍 부족: {len(valid_pairs)}/{count}\")\n",
    "\n",
    "            return valid_pairs\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    [재시도 {attempt + 1}/{max_retries}] {type(e).__name__}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                print(f\"    [실패] {axis} 축 배치 생성 실패\")\n",
    "                return []\n",
    "\n",
    "\n",
    "# 테스트: lore_revelation 5개\n",
    "test_pairs = generate_batch(\"lore_revelation\", count=5)\n",
    "print(f\"테스트 생성: {len(test_pairs)}개\")\n",
    "for p in test_pairs:\n",
    "    print(f\"  플레이어: {p['input']}\")\n",
    "    print(f\"  마가렛:   {p['output']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. 대비 쌍 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRAST_AXIS_PAIRS = [\n",
    "    (\"lore_revelation\", \"escape_warning\"),  # 진실 요구 ↔ 탈출 행동\n",
    "    (\"past_memory\",     \"horror_image\"),    # 과거 질문 ↔ 몸 상태 질문\n",
    "    (\"plea\",            \"escape_warning\"),  # 손잡기 ↔ 탈출 준비\n",
    "    (\"lore_revelation\", \"past_memory\"),     # 세계관 ↔ 과거 기억\n",
    "    (\"horror_image\",    \"plea\"),            # 몸 상태 접근 ↔ 도움 요청\n",
    "]\n",
    "\n",
    "\n",
    "def generate_contrast_batch(\n",
    "    axis_a: str,\n",
    "    axis_b: str,\n",
    "    count: int = 5,\n",
    "    temperature: float = 0.9,\n",
    "    max_retries: int = 3,\n",
    ") -> List[dict]:\n",
    "    info_a = AXIS_PROMPTS[axis_a]\n",
    "    info_b = AXIS_PROMPTS[axis_b]\n",
    "\n",
    "    user_prompt = f\"\"\"의미 대비 쌍 생성 요청.\n",
    "\n",
    "## 축 A: {info_a['name']} ({axis_a})\n",
    "{info_a['description']}\n",
    "\n",
    "## 축 B: {info_b['name']} ({axis_b})\n",
    "{info_b['description']}\n",
    "\n",
    "## 요청\n",
    "{count}개의 대비 쌍을 생성하라. 각 쌍은 비슷한 상황에서 플레이어가 다른 행동을 하고,\n",
    "마가렛은 각 축의 귀결 방향에 맞게 응답한다.\n",
    "\n",
    "JSON 형식:\n",
    "{{\"pairs\": [\n",
    "  {{\"a_input\": \"축A 플레이어 대사\", \"a_output\": \"축A 마가렛 발화\", \"b_input\": \"축B 플레이어 대사\", \"b_output\": \"축B 마가렛 발화\"}},\n",
    "  ...\n",
    "]}}\"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                temperature=temperature,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "            )\n",
    "\n",
    "            parsed = json.loads(response.choices[0].message.content)\n",
    "            raw_pairs = parsed.get(\"pairs\", parsed) if isinstance(parsed, dict) else parsed\n",
    "            if not isinstance(raw_pairs, list):\n",
    "                for key in parsed:\n",
    "                    if isinstance(parsed[key], list):\n",
    "                        raw_pairs = parsed[key]\n",
    "                        break\n",
    "\n",
    "            results = []\n",
    "            for p in raw_pairs:\n",
    "                if all(k in p for k in [\"a_input\", \"a_output\", \"b_input\", \"b_output\"]):\n",
    "                    results.append({\"input\": p[\"a_input\"], \"output\": p[\"a_output\"], \"_axis\": axis_a})\n",
    "                    results.append({\"input\": p[\"b_input\"], \"output\": p[\"b_output\"], \"_axis\": axis_b})\n",
    "            return results\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    [재시도 {attempt + 1}/{max_retries}] {type(e).__name__}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt)\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "\n",
    "print(\"대비 쌍 생성 함수 정의 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. 데이터 생성 엔진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(\n",
    "    num_samples: int = 400,\n",
    "    batch_size: int = 20,\n",
    "    temperature: float = 0.9,\n",
    "    contrast_per_pair: int = 5,\n",
    ") -> List[dict]:\n",
    "    data = []\n",
    "    axes = list(AXIS_PROMPTS.keys())\n",
    "\n",
    "    # 1단계: 의미 대비 쌍\n",
    "    print(\"[1/2] 의미 대비 쌍 생성...\")\n",
    "    for axis_a, axis_b in CONTRAST_AXIS_PAIRS:\n",
    "        print(f\"  대비: {axis_a} ↔ {axis_b}\")\n",
    "        pairs = generate_contrast_batch(axis_a, axis_b, count=contrast_per_pair, temperature=temperature)\n",
    "        data.extend(pairs)\n",
    "        print(f\"    → {len(pairs)}개 생성\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    print(f\"  대비 쌍 합계: {len(data)}개\")\n",
    "\n",
    "    # 2단계: 축별 균등 분배\n",
    "    print(f\"\\n[2/2] 축별 일반 생성...\")\n",
    "    remaining = num_samples - len(data)\n",
    "    per_axis = remaining // len(axes)\n",
    "    leftover = remaining % len(axes)\n",
    "\n",
    "    for i, axis in enumerate(axes):\n",
    "        target = per_axis + (1 if i < leftover else 0)\n",
    "        generated = 0\n",
    "        batch_num = 0\n",
    "\n",
    "        while generated < target:\n",
    "            batch_count = min(batch_size, target - generated)\n",
    "            batch_num += 1\n",
    "            print(f\"  {AXIS_PROMPTS[axis]['name']} 배치 {batch_num}: {batch_count}개 요청...\", end=\" \")\n",
    "            pairs = generate_batch(axis, count=batch_count, temperature=temperature)\n",
    "            data.extend(pairs)\n",
    "            generated += len(pairs)\n",
    "            print(f\"→ {len(pairs)}개 생성 (누적 {generated}/{target})\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    random.shuffle(data)\n",
    "    print(f\"\\n총 생성: {len(data)}개 (목표: {num_samples})\")\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"데이터 생성 함수 정의 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 7. 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_dataset(data: List[dict]) -> dict:\n",
    "    stats = {\n",
    "        \"total\": len(data),\n",
    "        \"axis_dist\": Counter(),\n",
    "        \"input_lengths\": [],\n",
    "        \"output_lengths\": [],\n",
    "        \"duplicates\": 0,\n",
    "    }\n",
    "    seen_inputs = set()\n",
    "    for item in data:\n",
    "        stats[\"axis_dist\"][item[\"_axis\"]] += 1\n",
    "        stats[\"input_lengths\"].append(len(item[\"input\"]))\n",
    "        stats[\"output_lengths\"].append(len(item[\"output\"]))\n",
    "        if item[\"input\"] in seen_inputs:\n",
    "            stats[\"duplicates\"] += 1\n",
    "        seen_inputs.add(item[\"input\"])\n",
    "    return stats\n",
    "\n",
    "\n",
    "def print_stats(stats: dict, set_name: str = \"Set\") -> None:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"  {set_name} 통계\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"  총 샘플 수: {stats['total']}\")\n",
    "    print(f\"  중복 input: {stats['duplicates']}\")\n",
    "    print(f\"\\n  [의미 축 분포]\")\n",
    "    for axis, count in sorted(stats[\"axis_dist\"].items()):\n",
    "        pct = count / stats[\"total\"] * 100\n",
    "        print(f\"    {axis:25s}: {count:4d} ({pct:.1f}%)\")\n",
    "    avg_in = sum(stats[\"input_lengths\"]) / len(stats[\"input_lengths\"])\n",
    "    avg_out = sum(stats[\"output_lengths\"]) / len(stats[\"output_lengths\"])\n",
    "    print(f\"\\n  [평균 길이]\")\n",
    "    print(f\"    input  평균: {avg_in:.1f}자\")\n",
    "    print(f\"    output 평균: {avg_out:.1f}자\")\n",
    "\n",
    "\n",
    "print(\"검증 함수 정의 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 8. 세트 1 생성 (400개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = generate_dataset(num_samples=400, temperature=0.9)\n",
    "\n",
    "stats1 = validate_dataset(set1)\n",
    "print_stats(stats1, \"세트 1\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"  세트 1 샘플 (축별 1개씩)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "shown_axes = set()\n",
    "for item in set1:\n",
    "    if item[\"_axis\"] not in shown_axes:\n",
    "        shown_axes.add(item[\"_axis\"])\n",
    "        print(f\"\\n  [{item['_axis']}]\")\n",
    "        print(f\"  플레이어: {item['input']}\")\n",
    "        print(f\"  마가렛:   {item['output']}\")\n",
    "    if len(shown_axes) == len(AXIS_PROMPTS):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 9. 세트 2 생성 (400개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "set2 = generate_dataset(num_samples=400, temperature=1.0)\n",
    "\n",
    "stats2 = validate_dataset(set2)\n",
    "print_stats(stats2, \"세트 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 10. JSONL 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(data: List[dict], output_path: str) -> None:\n",
    "    output_file = Path(output_path)\n",
    "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            clean = {\"input\": item[\"input\"], \"output\": item[\"output\"]}\n",
    "            f.write(json.dumps(clean, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"저장 완료: {output_path} ({len(data)}개)\")\n",
    "\n",
    "\n",
    "OUTPUT_DIR = Path(\"../data/grandmother\")\n",
    "\n",
    "save_jsonl(set1, str(OUTPUT_DIR / \"grandmother_dialogue_00.jsonl\"))\n",
    "save_jsonl(set2, str(OUTPUT_DIR / \"grandmother_dialogue_01.jsonl\"))\n",
    "\n",
    "combined = set1 + set2\n",
    "random.shuffle(combined)\n",
    "save_jsonl(combined, str(OUTPUT_DIR / \"grandmother_dialogue_combined.jsonl\"))\n",
    "print(f\"\\n합본 저장 완료: {len(combined)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## 11. 최종 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in [\"grandmother_dialogue_00.jsonl\", \"grandmother_dialogue_01.jsonl\", \"grandmother_dialogue_combined.jsonl\"]:\n",
    "    fpath = OUTPUT_DIR / fname\n",
    "    with open(fpath, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"{fname}: {len(lines)}줄\")\n",
    "    for i, line in enumerate(lines):\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            assert \"input\" in obj and \"output\" in obj\n",
    "            assert len(obj[\"output\"]) > 0\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR at line {i}: {e}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"  -> 파싱 검증 통과\")\n",
    "\n",
    "print(\"\\n=== 의미 축별 최종 샘플 ===\")\n",
    "axis_names_kr = {\n",
    "    \"lore_revelation\": \"세계관 설명\",\n",
    "    \"escape_warning\":  \"탈출 경고\",\n",
    "    \"horror_image\":    \"고어한 비유\",\n",
    "    \"past_memory\":     \"과거 기억\",\n",
    "    \"plea\":            \"도움 요청\",\n",
    "}\n",
    "for axis in AXIS_PROMPTS.keys():\n",
    "    axis_items = [item for item in combined if item[\"_axis\"] == axis]\n",
    "    samples = random.sample(axis_items, min(3, len(axis_items)))\n",
    "    print(f\"\\n--- {axis_names_kr.get(axis, axis)} ---\")\n",
    "    for s in samples:\n",
    "        print(f\"  플레이어: {s['input']}\")\n",
    "        print(f\"  마가렛:   {s['output']}\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
